{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, pickle\n",
    "import numpy as np\n",
    "from pmdarima.arima import AutoARIMA\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import date as dt, timedelta, datetime\n",
    "import yfinance as yf\n",
    "import pymysql\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import datetime as dt\n",
    "import pandas_datareader as web\n",
    "from dateutil.relativedelta import *\n",
    "import yfinance as yf\n",
    "from yahoofinancials import YahooFinancials\n",
    "from sqlalchemy import create_engine\n",
    "import mysql.connector\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "from feature_engine.selection import DropCorrelatedFeatures, SmartCorrelatedSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 124)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We got the combined dataset from another file\n",
    "df = pd.read_excel('test_8.4.xlsx', sheet_name='Sheet1')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_null(df, fraction=0.7):\n",
    "    \n",
    "#     df = pd.read_excel('test_8.4.xlsx')\n",
    "    \n",
    "    num_rows = len(df)\n",
    "    num_cols = df.shape[1]\n",
    "    \n",
    "    #Deleting the row that has 20 missing values of the complete columns\n",
    "    df.dropna(axis=0, thresh=len(df.columns)-5, inplace=True)\n",
    "    \n",
    "    #Deleting columns that has atleast certain % of missing value\n",
    "    df.dropna(axis=1, thresh=fraction, inplace=True)\n",
    "    \n",
    "    #Drop columns & rows with all null values \n",
    "    df.dropna(how='all', inplace=True, axis=1)\n",
    "    df.dropna(how='all', inplace=True, axis=0)\n",
    "    \n",
    "    return df, num_rows, num_cols\n",
    "\n",
    "df, num_rows, num_cols = remove_null(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_impute(df1):\n",
    "    \n",
    "    df, num_rows, num_cols = remove_null(df1)\n",
    "    \n",
    "    df.drop(columns=['perc_change', 'time_tod', 'Latest Earnings', 'Price/Cash Flow'], inplace=True)\n",
    "\n",
    "    cat_list = df.select_dtypes('O').columns.to_list()\n",
    "    num_list = list(set(df.columns.to_list()).difference(set(cat_list)))\n",
    "    print(f'B4 transformation length of cat: {len(cat_list)}, len of num: {len(num_list)}')\n",
    "          \n",
    "    #for categorical variable, cleaning ones with % & , and converting them to float\n",
    "    df.replace(['unch'], 0, inplace=True)\n",
    "    for col in df.select_dtypes('O').columns.to_list():\n",
    "\n",
    "        df[col] = df[col].str.replace(r'%', \"\")\n",
    "        df[col] = df[col].str.replace(r',', \"\")\n",
    "\n",
    "        try:\n",
    "            df[col] = df[col].astype('float')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    df['Trend Str'].fillna('Average', inplace=True)\n",
    "    \n",
    "    #for numeric variables\n",
    "    df['% Institutional'].fillna(50, inplace=True)\n",
    "    df['% Insider'].fillna(10, inplace=True)\n",
    "    df['EPS Growth Prv(q)'].fillna(0, inplace=True)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col.endswith('Qtrs Ago'):\n",
    "            df[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df.dropna(axis=0, inplace = True)\n",
    "    \n",
    "    new_rows, new_cols = df.shape[0], df.shape[1]\n",
    "    num_rows_dropped, num_cols_dropped = num_rows - new_rows, num_cols - new_cols\n",
    "    \n",
    "    cat_list = df.select_dtypes('O').columns.to_list()\n",
    "    num_list = list(set(df.columns.to_list()).difference(set(cat_list)))\n",
    "    \n",
    "    print(f'After transformation length of cat: {len(cat_list)}, len of num: {len(num_list)}')\n",
    "    \n",
    "    print(f'number of rows dropped: {num_rows_dropped}')\n",
    "    print(f'number of cols dropped: {num_cols_dropped}')\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B4 transformation length of cat: 64, len of num: 56\n",
      "After transformation length of cat: 15, len of num: 105\n",
      "number of rows dropped: 13\n",
      "number of cols dropped: 4\n"
     ]
    }
   ],
   "source": [
    "df = clean_impute(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyst_col_clean(df):\n",
    "    \n",
    "    #Shorten this code when you have time\n",
    "\n",
    "    ap_list, lw_list, mt_list = [], [], []\n",
    "    \n",
    "    op_list = list(df['Opinion'].values)\n",
    "    for item in op_list:\n",
    "        try:\n",
    "            new = item.split(\" \")[1]\n",
    "            value = item.split(\" \")[0]\n",
    "\n",
    "            if new == 'Buy':\n",
    "                value = int(value)*1\n",
    "            elif new == 'Sell':\n",
    "                value = int(value)* -1\n",
    "\n",
    "        except:\n",
    "            value = 0 \n",
    "\n",
    "\n",
    "        ap_list.append(value)\n",
    "\n",
    "\n",
    "    lw_list_o = list(df['Last Week'].values)\n",
    "    for item in lw_list_o:\n",
    "        try:\n",
    "            new = item.split(\" \")[1]\n",
    "            value = item.split(\" \")[0]\n",
    "\n",
    "            if new == 'Buy':\n",
    "                value = int(value)*1\n",
    "            elif new == 'Sell':\n",
    "                value = int(value)* -1\n",
    "\n",
    "        except:\n",
    "            value = 0 \n",
    "\n",
    "\n",
    "        lw_list.append(value)\n",
    "\n",
    "    mt_list_o = list(df['Medium Term'].values)\n",
    "    for item in mt_list_o:\n",
    "        try:\n",
    "            new = item.split(\" \")[1]\n",
    "            value = item.split(\" \")[0]\n",
    "\n",
    "            if new == 'Buy':\n",
    "                value = int(value)*1\n",
    "            elif new == 'Sell':\n",
    "                value = int(value)* -1\n",
    "\n",
    "        except:\n",
    "            value = 0 \n",
    "\n",
    "\n",
    "        mt_list.append(value)\n",
    "        \n",
    "    df['Opinion'], df['Last Week'], df['Medium Term'] = ap_list, lw_list, mt_list\n",
    "    opinion_cols = ['Opinion', 'Last Week', 'Medium Term']\n",
    "    \n",
    "    for col in opinion_cols:\n",
    "        df[col] = df[col].astype('float')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = analyst_col_clean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Analyst Rating</th>\n",
       "      <th># Analysts</th>\n",
       "      <th>Earnings Est</th>\n",
       "      <th>Earnings Est 2-Qtrs Ago</th>\n",
       "      <th>Earnings Est 3-Qtrs Ago</th>\n",
       "      <th>Earnings Est 4-Qtrs Ago</th>\n",
       "      <th>Reported</th>\n",
       "      <th>Reported 2-Qtrs Ago</th>\n",
       "      <th>Reported 3-Qtrs Ago</th>\n",
       "      <th>...</th>\n",
       "      <th>20D MA</th>\n",
       "      <th>20D MA Str</th>\n",
       "      <th>50D MA</th>\n",
       "      <th>50D MA Str</th>\n",
       "      <th>20-50D MACD</th>\n",
       "      <th>Opinion</th>\n",
       "      <th>Prev Signal</th>\n",
       "      <th>Last Week</th>\n",
       "      <th>Medium Term</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACLS</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.81</td>\n",
       "      <td>...</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Maximum</td>\n",
       "      <td>Buy</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Buy</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADTN</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Average</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Maximum</td>\n",
       "      <td>Buy</td>\n",
       "      <td>88.0</td>\n",
       "      <td>Buy</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALG</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.59</td>\n",
       "      <td>...</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Soft</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Soft</td>\n",
       "      <td>Buy</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>Sell</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMOT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.41</td>\n",
       "      <td>...</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Maximum</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Buy</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>Sell</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ANIK</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Soft</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Soft</td>\n",
       "      <td>Buy</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>Sell</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol  Analyst Rating  # Analysts  Earnings Est  Earnings Est 2-Qtrs Ago  \\\n",
       "0   ACLS             4.8           5          0.92                     0.84   \n",
       "1   ADTN             4.4           5          0.02                    -0.06   \n",
       "3    ALG             3.0           1          1.69                     0.00   \n",
       "4   AMOT             5.0           1          0.09                     0.30   \n",
       "6   ANIK             3.0           2         -0.24                     0.00   \n",
       "\n",
       "   Earnings Est 3-Qtrs Ago  Earnings Est 4-Qtrs Ago  Reported  \\\n",
       "0                     0.71                     0.45      1.22   \n",
       "1                     0.14                     0.12      0.17   \n",
       "3                     1.98                     1.56      1.63   \n",
       "4                     0.30                     0.26      0.24   \n",
       "6                     0.08                     0.04     -0.11   \n",
       "\n",
       "   Reported 2-Qtrs Ago  Reported 3-Qtrs Ago  ...  20D MA  20D MA Str  50D MA  \\\n",
       "0                 1.05                 0.81  ...     Buy      Strong     Buy   \n",
       "1                 0.06                -0.06  ...     Buy     Average     Buy   \n",
       "3                 0.00                 1.59  ...     Buy        Soft     Buy   \n",
       "4                 0.20                 0.41  ...     Buy     Maximum     Buy   \n",
       "6                -0.23                 0.05  ...     Buy        Soft     Buy   \n",
       "\n",
       "   50D MA Str  20-50D MACD  Opinion  Prev Signal  Last Week  Medium Term  \\\n",
       "0     Maximum          Buy     24.0          Buy       -8.0        -50.0   \n",
       "1     Maximum          Buy     88.0          Buy       56.0        100.0   \n",
       "3        Soft          Buy    -24.0         Sell      -40.0        -50.0   \n",
       "4      Strong          Buy    -24.0         Sell      -40.0        -50.0   \n",
       "6        Soft          Buy    -24.0         Sell      -24.0        -50.0   \n",
       "\n",
       "   Target  \n",
       "0       1  \n",
       "1       0  \n",
       "3       1  \n",
       "4       1  \n",
       "6       0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(df):\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    cate_list = new_df.select_dtypes(include='O').columns.to_list()[1:] # We don't want the symbol\n",
    "    new_df[cate_list] = new_df[cate_list].apply(lambda x: le.fit_transform(x.astype(str)))\n",
    "    \n",
    "    pickle.dump(le, open('label_encoder.pkl', 'wb'))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158, 120)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = label_encoder(new_df)\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From feature Engine removing correlated features - this method is much easier than above\n",
    "fe_corr = DropCorrelatedFeatures(threshold=0.9, method='pearson', missing_values='ignore')\n",
    "new_df = fe_corr.fit_transform(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158, 82)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Earnings',\n",
       "  'Earnings Est',\n",
       "  'Earnings Est 2-Qtrs Ago',\n",
       "  'Earnings ttm',\n",
       "  'Reported',\n",
       "  'Reported 2-Qtrs Ago'},\n",
       " {'Earnings Est 3-Qtrs Ago',\n",
       "  'Earnings Est 4-Qtrs Ago',\n",
       "  'Reported 3-Qtrs Ago',\n",
       "  'Reported 4-Qtrs Ago'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe_corr.correlated_feature_sets_[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(new_df):\n",
    "\n",
    "# scaler= MinMaxScaler()\n",
    "\n",
    "    X, y = new_df.iloc[:,1:-1], new_df.iloc[:,-1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42,shuffle=True, stratify=y)\n",
    "    \n",
    "    return new_df, X_train, X_test, y_train, y_test, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df, X_train, X_test, y_train, y_test, X, y =  train_test(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if we have any duplicate columns meaning two columns having same value\n",
    "def getDuplicateColumns(df):\n",
    "    \n",
    "    dup_col = {}  \n",
    "    duplicateColumnNames = set()\n",
    "    for x in range(df.shape[1]):\n",
    "\n",
    "        col = df.iloc[:, x]\n",
    "        column_name = col.name\n",
    "          \n",
    "        for y in range(x + 1, df.shape[1]):\n",
    "            otherCol = df.iloc[:, y]\n",
    "            other_col_name = otherCol.name\n",
    "              \n",
    "            if col.equals(otherCol):\n",
    "                duplicateColumnNames.add(df.columns.values[y])\n",
    "                dup_col[column_name] = other_col_name\n",
    "                  \n",
    "    return dup_col #,list(duplicateColumnNames)\n",
    "\n",
    "getDuplicateColumns(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Constant and Quasi Constant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "features with constant values in X_train & X_test ['Options'], ['Options']\n"
     ]
    }
   ],
   "source": [
    "def removing_constant(X_train, X_test):\n",
    "\n",
    "    X_train_constant = [feat for feat in X_train.columns if X_train[feat].nunique() == 1]\n",
    "    X_test_constant = [feat for feat in X_test.columns if X_test[feat].nunique() == 1]\n",
    "    print(len(X_train_constant), len(X_test_constant))\n",
    "    print(f'features with constant values in X_train & X_test {X_train_constant}, {X_test_constant}')\n",
    "\n",
    "    X_train.drop(columns=X_train_constant, inplace=True)\n",
    "    X_test.drop(columns=X_test_constant, inplace=True)\n",
    "    \n",
    "    #Removing quasi-Constant feature with variance Threshold\n",
    "    vt = VarianceThreshold(threshold=0.02)\n",
    "    vt.fit(X_test)\n",
    "    vt.fit(X_train)\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "X_train, X_test = removing_constant(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105, 79), (53, 79))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection by SFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector as SFS\n",
    "sfs = SFS(\n",
    "    estimator=RandomForestClassifier(\n",
    "    n_estimators=10, n_jobs=4, random_state=0),\n",
    "    n_features_to_select=10,  # the number of features to retain\n",
    "    direction='forward',  # the direction of the selection procedure\n",
    "    scoring='roc_auc',  # the metric to evaluate\n",
    "    cv=2,  # the cross-validation fold\n",
    "    n_jobs=4,  # for parallelization\n",
    ")\n",
    "\n",
    "sfs = sfs.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score, accuracy_score\n",
    "DT = DecisionTreeClassifier().fit(X_train,y_train)\n",
    "\n",
    "params_grid = {'max_depth':range(1, DT.tree_.max_depth+1, 2),\n",
    "               'max_features':range(1,len(DT.feature_importances_)+1)\n",
    "              }\n",
    "\n",
    "DT_GV = GridSearchCV(DecisionTreeClassifier(random_state=101),\n",
    "                   param_grid=params_grid,\n",
    "                   scoring='accuracy',\n",
    "                   n_jobs=-1)\n",
    "\n",
    "DT_GV = DT_GV.fit(X_train,y_train)\n",
    "y_predDT = DT_GV.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.43      0.44        28\n",
      "           1       0.38      0.40      0.39        25\n",
      "\n",
      "    accuracy                           0.42        53\n",
      "   macro avg       0.41      0.41      0.41        53\n",
      "weighted avg       0.42      0.42      0.42        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_predDT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.32      0.35        28\n",
      "           1       0.37      0.44      0.40        25\n",
      "\n",
      "    accuracy                           0.38        53\n",
      "   macro avg       0.38      0.38      0.38        53\n",
      "weighted avg       0.38      0.38      0.38        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adaboost\n",
    "parameters = {'learning_rate': [ 0.5, 0.2, 0.1, 0.01, 0.001], \n",
    "              #'subsample':[1.0, 0.5,0.2], \n",
    "              #'max_features':[4, 5, 10, 12, 19],\n",
    "              'n_estimators':[15, 20, 30, 40, 80, 100, 200, 400]\n",
    "             }\n",
    "\n",
    "AB = GridSearchCV(AdaBoostClassifier(), param_grid=parameters, scoring='accuracy', n_jobs=-1)\n",
    "AB = AB.fit(X_train,y_train)\n",
    "y_predAB = AB.predict(X_test)\n",
    "print(classification_report(y_test,y_predAB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
